"""
Article Writer - generovani clanku z TOP temat
Stahne zdrojove clanky, posle do Claude a vygeneruje CZ + EN verzi
"""

import re
import requests
import anthropic
from bs4 import BeautifulSoup
from typing import List, Dict, Optional

import config


def scrape_full_article(url: str) -> str:
    """
    Stahne plny text clanku z URL

    Args:
        url: URL clanku

    Returns:
        Text clanku (max 3000 znaku)
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        resp = requests.get(url, headers=headers, timeout=15)
        resp.raise_for_status()

        soup = BeautifulSoup(resp.text, 'html.parser')

        # Odstran scripty a styly
        for tag in soup(['script', 'style', 'nav', 'footer', 'header', 'aside', 'iframe', 'noscript']):
            tag.decompose()

        # Zkus najit hlavni obsah
        content = None
        for selector in ['article', 'main', '[role="main"]', '.article-body', '.post-content', '.entry-content']:
            content = soup.select_one(selector)
            if content:
                break

        if not content:
            content = soup.body if soup.body else soup

        text = content.get_text(separator='\n', strip=True)

        # Vycisti prazdne radky
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        text = '\n'.join(lines)

        return text[:3000]

    except Exception as e:
        return f"[Chyba pri stahovani: {e}]"


def parse_topics_from_report(report_text: str) -> List[Dict]:
    """
    Parsuje text reportu na strukturovana temata

    Args:
        report_text: Plny text report.txt

    Returns:
        List slovniku s tematy
    """
    topics = []

    # Rozdeleni na bloky podle ğŸ® TÃ‰MA:
    blocks = re.split(r'(?=ğŸ® TÃ‰MA:)', report_text)

    for block in blocks:
        block = block.strip()
        if not block.startswith('ğŸ® TÃ‰MA:'):
            continue

        topic = {}

        # Parsuj jednotlive sekce
        patterns = {
            'topic': r'ğŸ® TÃ‰MA:\s*(.+)',
            'title': r'ğŸ“° NAVRÅ½ENÃ TITULEK:\s*(.+)',
            'angle': r'ğŸ¯ ÃšHEL POHLEDU:\s*(.+)',
            'context': r'ğŸ“ KONTEXT:\s*(.+)',
            'hook': r'ğŸ’¬ HLAVNÃ HOOK:\s*(.+)',
            'visual': r'ğŸ–¼ï¸ VIZUÃLNÃ NÃVRH:\s*(.+)',
            'virality': r'ğŸ”¥ VIRALITA:\s*(.+)',
            'why_now': r'ğŸ’¡ PROÄŒ TEÄKA:\s*(.+)',
            'seo_keywords': r'ğŸ·ï¸ SEO KLÃÄŒOVÃ SLOVA:\s*(.+)',
        }

        for key, pattern in patterns.items():
            match = re.search(pattern, block)
            topic[key] = match.group(1).strip() if match else ''

        # Parsuj virality score jako cislo
        virality_match = re.search(r'(\d+)', topic.get('virality', ''))
        topic['virality_score'] = int(virality_match.group(1)) if virality_match else 0

        # Parsuj zdroje (URL na samostatnych radcich)
        sources_section = re.search(r'ğŸ”— ZDROJE:\s*\n?([\s\S]*?)(?=ğŸ·ï¸|$)', block)
        if sources_section:
            urls = re.findall(r'https?://[^\s<>"\')\]]+[^\s<>"\')\].,]', sources_section.group(1))
            topic['sources'] = urls
        else:
            topic['sources'] = []

        if topic.get('topic'):
            topics.append(topic)

    return topics


def write_article(topic: Dict, source_texts: List[str]) -> Dict:
    """
    Vygeneruje clanek pomoci Claude API

    Args:
        topic: Slovnik s tematem (z parse_topics_from_report)
        source_texts: Seznam plnych textu zdrojovych clanku

    Returns:
        {"cs": "<html>...", "en": "<html>..."} nebo {"error": "..."}
    """
    client = anthropic.Anthropic(api_key=config.CLAUDE_API_KEY)

    # Pripravi zdrojove texty
    sources_combined = ""
    for i, text in enumerate(source_texts, 1):
        sources_combined += f"\n--- ZDROJ {i} ---\n{text}\n"

    # Pripravi seznam URL zdroju pro konec clanku
    source_urls = topic.get('sources', [])
    sources_list = "\n".join(source_urls)

    prompt = f"""NapÃ­Å¡ originÃ¡lnÃ­ hernÃ­ ÄlÃ¡nek na zÃ¡kladÄ› zdrojovÃ½ch textÅ¯.

TÃ‰MA: {topic.get('topic', '')}
NAVRÅ½ENÃ TITULEK: {topic.get('title', '')}
ÃšHEL POHLEDU: {topic.get('angle', '')}
KONTEXT: {topic.get('context', '')}
SEO KLÃÄŒOVÃ SLOVA: {topic.get('seo_keywords', '')}

ZDROJOVÃ‰ TEXTY:
{sources_combined}

PRAVIDLA:
- PiÅ¡ VLASTNÃMI SLOVY, ne kopÃ­ruj ze zdrojÅ¯
- ÄŒlÃ¡nek musÃ­ mÃ­t 600-1000 slov
- FormÃ¡t: HTML (h2 nadpisy, p odstavce, strong pro dÅ¯leÅ¾itÃ©)
- Styl: informativnÃ­, poutavÃ½, pro ÄeskÃ© hernÃ­ publikum
- ZahrÅˆ konkrÃ©tnÃ­ fakta a ÄÃ­sla ze zdrojÅ¯
- NEZMIÅ‡UJ zdroje v textu ÄlÃ¡nku (ne "podle IGN...")
- NEPÅ˜IDÃVEJ h1 nadpis - ten bude jako titulek ÄlÃ¡nku
- KRITICKÃ‰: V nadpisech (h2) NEPOUÅ½ÃVEJ Title Case! VelkÃ© pÃ­smeno POUZE na zaÄÃ¡tku vÄ›ty a u vlastnÃ­ch jmen. Å PATNÄš: "NovÃ¡ Ã‰ra Pro HernÃ­ PrÅ¯mysl". SPRÃVNÄš: "NovÃ¡ Ã©ra pro hernÃ­ prÅ¯mysl". Å PATNÄš: "What This Means For Players". SPRÃVNÄš: "What this means for players".
- Na konec ÄlÃ¡nku VÅ½DY pÅ™idej sekci "Zdroje" (v EN "Sources") jako HTML seznam odkazÅ¯

ZDROJOVÃ‰ URL PRO SEKCI ZDROJE:
{sources_list}

POSTUP:
1. NejdÅ™Ã­v napiÅ¡ ÄlÃ¡nek v ÄŒEÅ TINÄš
2. Na konec ÄeskÃ© verze pÅ™idej <h2>Zdroje</h2> s odkazy jako <ul><li><a href="URL">nÃ¡zev webu</a></li></ul>
3. Potom PÅ˜ELOÅ½ celÃ½ ÄlÃ¡nek do angliÄtiny vÄetnÄ› sekce zdrojÅ¯ (nadpis "Sources")

=== ÄŒESKY ===
<ÄlÃ¡nek v ÄeÅ¡tinÄ› jako HTML, na konci sekce Zdroje s odkazy>

=== ENGLISH ===
<pÅ™esnÃ½ pÅ™eklad ÄeskÃ©ho ÄlÃ¡nku vÃ½Å¡e, na konci sekce Sources s odkazy>"""

    try:
        message = client.messages.create(
            model=config.ARTICLE_MODEL,
            max_tokens=8000,
            temperature=0.7,
            messages=[{
                "role": "user",
                "content": prompt
            }]
        )

        result_text = message.content[0].text

        # Parsuj CZ a EN casti
        cs_match = re.search(r'===\s*ÄŒESKY\s*===\s*([\s\S]*?)(?====\s*ENGLISH\s*===|$)', result_text)
        en_match = re.search(r'===\s*ENGLISH\s*===\s*([\s\S]*?)$', result_text)

        cs_html = cs_match.group(1).strip() if cs_match else result_text
        en_html = en_match.group(1).strip() if en_match else ''

        # Odhad ceny
        cost_input = (message.usage.input_tokens / 1_000_000) * 0.25
        cost_output = (message.usage.output_tokens / 1_000_000) * 1.25
        total_cost = cost_input + cost_output

        return {
            'cs': cs_html,
            'en': en_html,
            'tokens_in': message.usage.input_tokens,
            'tokens_out': message.usage.output_tokens,
            'cost': f"${total_cost:.4f}"
        }

    except Exception as e:
        return {'error': str(e)}
