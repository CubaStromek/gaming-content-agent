"""
Article Writer - generovani clanku z TOP temat
Stahne zdrojove clanky, posle do Claude a vygeneruje CZ + EN verzi
"""

import re
import requests
import anthropic
from bs4 import BeautifulSoup
from typing import List, Dict, Optional

import config
from urllib.parse import urlparse


def _build_sources_html(source_urls: List[str], lang: str = 'cs') -> str:
    """SestavÃ­ HTML sekci zdrojÅ¯ z reÃ¡lnÃ½ch URL."""
    if not source_urls:
        return ''

    heading = 'Zdroje' if lang == 'cs' else 'Sources'
    items = []
    for url in source_urls:
        try:
            domain = urlparse(url).netloc.replace('www.', '')
        except Exception:
            domain = url
        items.append(f'<li><a href="{url}" target="_blank" rel="noopener">{domain}</a></li>')

    return f'\n<h2>{heading}</h2>\n<ul>\n' + '\n'.join(items) + '\n</ul>'


def _strip_generated_sources(html: str) -> str:
    """OdstranÃ­ AI-generovanou sekci zdrojÅ¯ (Zdroje/Sources) pokud existuje."""
    # OdstranÃ­ <h2>Zdroje</h2> nebo <h2>Sources</h2> a nÃ¡sledujÃ­cÃ­ <ul>...</ul>
    return re.sub(
        r'\s*<h2>\s*(?:Zdroje|Sources)\s*</h2>\s*<ul>[\s\S]*?</ul>\s*',
        '',
        html,
        flags=re.IGNORECASE
    )


def _strip_markdown_artifacts(html: str) -> str:
    """OdstranÃ­ markdown artefakty, kterÃ© Haiku obÄas pÅ™idÃ¡ do HTML vÃ½stupu."""
    # OdstraÅˆ ```html ... ``` code fences
    html = re.sub(r'```html\s*\n?', '', html)
    html = re.sub(r'```\s*$', '', html, flags=re.MULTILINE)
    # PÅ™eveÄ markdown nadpisy (## Nadpis) na <h2>
    html = re.sub(r'^#{3,}\s+(.+)$', r'<h3>\1</h3>', html, flags=re.MULTILINE)
    html = re.sub(r'^#{2}\s+(.+)$', r'<h2>\1</h2>', html, flags=re.MULTILINE)
    html = re.sub(r'^#\s+(.+)$', r'<h2>\1</h2>', html, flags=re.MULTILINE)
    # PÅ™eveÄ markdown --- na <hr>
    html = re.sub(r'^-{3,}\s*$', '<hr>', html, flags=re.MULTILINE)
    # PÅ™eveÄ **bold** na <strong>
    html = re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', html)
    return html.strip()


def scrape_full_article(url: str) -> str:
    """
    Stahne plny text clanku z URL

    Args:
        url: URL clanku

    Returns:
        Text clanku (max 3000 znaku)
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        resp = requests.get(url, headers=headers, timeout=15)
        resp.raise_for_status()

        soup = BeautifulSoup(resp.text, 'html.parser')

        # Odstran scripty a styly
        for tag in soup(['script', 'style', 'nav', 'footer', 'header', 'aside', 'iframe', 'noscript']):
            tag.decompose()

        # Zkus najit hlavni obsah
        content = None
        for selector in ['article', 'main', '[role="main"]', '.article-body', '.post-content', '.entry-content']:
            content = soup.select_one(selector)
            if content:
                break

        if not content:
            content = soup.body if soup.body else soup

        text = content.get_text(separator='\n', strip=True)

        # Vycisti prazdne radky
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        text = '\n'.join(lines)

        return text[:3000]

    except Exception as e:
        return f"[Chyba pri stahovani: {e}]"


def parse_topics_from_report(report_text: str) -> List[Dict]:
    """
    Parsuje text reportu na strukturovana temata

    Args:
        report_text: Plny text report.txt

    Returns:
        List slovniku s tematy
    """
    topics = []

    # Rozdeleni na bloky podle ğŸ® TÃ‰MA (s volitelnym cislem, toleruje **bold**)
    blocks = re.split(r'(?=ğŸ®\s*\*{0,2}\s*TÃ‰MA\s*\d*:\*{0,2})', report_text)

    for block in blocks:
        block = block.strip()
        if not re.match(r'.*ğŸ®\s*\*{0,2}\s*TÃ‰MA\s*\d*:\*{0,2}', block):
            continue

        topic = {}

        # Parsuj jednotlive sekce
        # Patterny toleruji markdown bold (**) pred emoji i kolem labelu
        # a obsah muze byt na stejnem radku nebo na nasledujicim
        _val = r'\s*\n?\s*(.+)'
        patterns = {
            'topic': r'\*{0,2}ğŸ®\s*\*{0,2}\s*TÃ‰MA\s*\d*:\*{0,2}' + _val,
            'title': r'\*{0,2}ğŸ“°\s*\*{0,2}\s*NAVRÅ½ENÃ TITULEK:\*{0,2}' + _val,
            'angle': r'\*{0,2}ğŸ¯\s*\*{0,2}\s*ÃšHEL POHLEDU:\*{0,2}' + _val,
            'context': r'\*{0,2}ğŸ“\s*\*{0,2}\s*KONTEXT:\*{0,2}' + _val,
            'hook': r'\*{0,2}ğŸ’¬\s*\*{0,2}\s*HLAVNÃ HOOK:\*{0,2}' + _val,
            'visual': r'\*{0,2}ğŸ–¼ï¸\s*\*{0,2}\s*VIZUÃLNÃ NÃVRH:\*{0,2}' + _val,
            'virality': r'\*{0,2}ğŸ”¥\s*\*{0,2}\s*VIRALITA:\*{0,2}' + _val,
            'why_now': r'\*{0,2}ğŸ’¡\s*\*{0,2}\s*PROÄŒ TEÄKA:\*{0,2}' + _val,
            'seo_keywords': r'\*{0,2}ğŸ·ï¸\s*\*{0,2}\s*SEO KLÃÄŒOVÃ SLOVA:\*{0,2}' + _val,
        }

        for key, pattern in patterns.items():
            match = re.search(pattern, block)
            value = match.group(1).strip() if match else ''
            # Odstranit uvozovky a markdown bold z hodnoty
            value = value.strip('"\'').strip('*')
            topic[key] = value

        # Parsuj virality score jako cislo
        virality_match = re.search(r'(\d+)', topic.get('virality', ''))
        topic['virality_score'] = int(virality_match.group(1)) if virality_match else 0

        # Parsuj zdroje (URL na samostatnych radcich)
        sources_section = re.search(r'\*{0,2}ğŸ”—\s*\*{0,2}\s*ZDROJE:\*{0,2}\s*\n?([\s\S]*?)(?=\*{0,2}ğŸ·ï¸|$)', block)
        if sources_section:
            urls = re.findall(r'https?://[^\s<>"\')\]]+[^\s<>"\')\].,]', sources_section.group(1))
            topic['sources'] = urls
        else:
            topic['sources'] = []

        if topic.get('topic'):
            topics.append(topic)

    return topics


def write_article(topic: Dict, source_texts: List[str], length: str = 'medium') -> Dict:
    """
    Vygeneruje clanek pomoci Claude API

    Args:
        topic: Slovnik s tematem (z parse_topics_from_report)
        source_texts: Seznam plnych textu zdrojovych clanku

    Returns:
        {"cs": "<html>...", "en": "<html>..."} nebo {"error": "..."}
    """
    client = anthropic.Anthropic(api_key=config.CLAUDE_API_KEY)

    # Pripravi zdrojove texty
    sources_combined = ""
    for i, text in enumerate(source_texts, 1):
        sources_combined += f"\n--- ZDROJ {i} ---\n{text}\n"

    # Pripravi seznam URL zdroju pro konec clanku
    source_urls = topic.get('sources', [])
    sources_list = "\n".join(source_urls)

    if length == 'short':
        length_instruction = "ÄŒlÃ¡nek musÃ­ mÃ­t 400-800 znakÅ¯ (krÃ¡tkÃ¡ zprÃ¡va, 2-3 odstavce)"
    else:
        length_instruction = "ÄŒlÃ¡nek musÃ­ mÃ­t 1000-2000 znakÅ¯ (stÅ™ednÃ­ dÃ©lka, 4-6 odstavcÅ¯)"

    prompt = f"""NapÃ­Å¡ originÃ¡lnÃ­ hernÃ­ ÄlÃ¡nek na zÃ¡kladÄ› zdrojovÃ½ch textÅ¯.

TÃ‰MA: {topic.get('topic', '')}
NAVRÅ½ENÃ TITULEK: {topic.get('title', '')}
ÃšHEL POHLEDU: {topic.get('angle', '')}
KONTEXT: {topic.get('context', '')}
SEO KLÃÄŒOVÃ SLOVA: {topic.get('seo_keywords', '')}

ZDROJOVÃ‰ TEXTY:
{sources_combined}

PRAVIDLA:
- PiÅ¡ VLASTNÃMI SLOVY, ne kopÃ­ruj ze zdrojÅ¯
- {length_instruction}
- FormÃ¡t: ÄŒISTÃ‰ HTML (h2 nadpisy, p odstavce, strong pro dÅ¯leÅ¾itÃ©)
- NEPOUÅ½ÃVEJ markdown! Å½Ã¡dnÃ© ```, ---, #, ** â€” POUZE HTML tagy
- Styl: informativnÃ­, poutavÃ½, pro ÄeskÃ© hernÃ­ publikum
- ZahrÅˆ konkrÃ©tnÃ­ fakta a ÄÃ­sla ze zdrojÅ¯
- NEZMIÅ‡UJ zdroje v textu ÄlÃ¡nku (ne "podle IGN...")
- NEPÅ˜IDÃVEJ h1 nadpis - ten bude jako titulek ÄlÃ¡nku
- KRITICKÃ‰: V nadpisech (h2) NEPOUÅ½ÃVEJ Title Case! VelkÃ© pÃ­smeno POUZE na zaÄÃ¡tku vÄ›ty a u vlastnÃ­ch jmen. Å PATNÄš: "NovÃ¡ Ã‰ra Pro HernÃ­ PrÅ¯mysl". SPRÃVNÄš: "NovÃ¡ Ã©ra pro hernÃ­ prÅ¯mysl". Å PATNÄš: "What This Means For Players". SPRÃVNÄš: "What this means for players".
- NEPÅ˜IDÃVEJ sekci "Zdroje" ani "Sources" â€” odkazy na zdroje se pÅ™idajÃ­ automaticky

POSTUP:
1. NejdÅ™Ã­v napiÅ¡ ÄlÃ¡nek v ÄŒEÅ TINÄš (BEZ sekce zdrojÅ¯)
2. Potom PÅ˜ELOÅ½ celÃ½ ÄlÃ¡nek do angliÄtiny

=== ÄŒESKY ===
<ÄlÃ¡nek v ÄeÅ¡tinÄ› jako HTML>

=== ENGLISH ===
<pÅ™esnÃ½ pÅ™eklad ÄeskÃ©ho ÄlÃ¡nku vÃ½Å¡e>"""

    try:
        message = client.messages.create(
            model=config.ARTICLE_MODEL,
            max_tokens=4096,
            temperature=0.7,
            messages=[{
                "role": "user",
                "content": prompt
            }]
        )

        result_text = message.content[0].text

        # Parsuj CZ a EN casti
        cs_match = re.search(r'===\s*ÄŒESKY\s*===\s*([\s\S]*?)(?====\s*ENGLISH\s*===|$)', result_text)
        en_match = re.search(r'===\s*ENGLISH\s*===\s*([\s\S]*?)$', result_text)

        if cs_match:
            cs_html = cs_match.group(1).strip()
        elif en_match:
            cs_html = result_text[:en_match.start()].strip()
        else:
            cs_html = result_text
        en_html = en_match.group(1).strip() if en_match else ''

        # VyÄisti markdown artefakty (Haiku 3.5 je obÄas pÅ™idÃ¡vÃ¡)
        cs_html = _strip_markdown_artifacts(cs_html)
        if en_html:
            en_html = _strip_markdown_artifacts(en_html)

        # OdstraÅˆ AI-generovanÃ© zdroje a pÅ™ipoj reÃ¡lnÃ© URL
        cs_html = _strip_generated_sources(cs_html)
        cs_html += _build_sources_html(source_urls, 'cs')

        if en_html:
            en_html = _strip_generated_sources(en_html)
            en_html += _build_sources_html(source_urls, 'en')

        # Odhad ceny (Claude Haiku 4.5 pricing: $1.00/MTok input, $5.00/MTok output)
        cost_input = (message.usage.input_tokens / 1_000_000) * 1.00
        cost_output = (message.usage.output_tokens / 1_000_000) * 5.00
        total_cost = cost_input + cost_output

        return {
            'cs': cs_html,
            'en': en_html,
            'tokens_in': message.usage.input_tokens,
            'tokens_out': message.usage.output_tokens,
            'cost': f"${total_cost:.4f}"
        }

    except Exception as e:
        return {'error': str(e)}


def generate_podcast_script(article_html: str, lang: str = 'cs') -> Dict:
    """
    Vygeneruje podcast script ze clanku (styl NotebookLM - 2 moderatori)

    Args:
        article_html: HTML obsah clanku
        lang: 'cs' pro cestinu, 'en' pro anglictinu

    Returns:
        {"script": "...", "tokens_in": ..., "tokens_out": ..., "cost": "..."} nebo {"error": "..."}
    """
    client = anthropic.Anthropic(api_key=config.CLAUDE_API_KEY)

    # Odstran HTML tagy pro citelnejsi vstup
    from bs4 import BeautifulSoup
    soup = BeautifulSoup(article_html, 'html.parser')
    article_text = soup.get_text(separator='\n', strip=True)

    if lang == 'cs':
        prompt = f"""VytvoÅ™ podcast script ze nÃ¡sledujÃ­cÃ­ho ÄlÃ¡nku. FormÃ¡t: konverzace dvou moderÃ¡torÅ¯ (ALEX a MAYA).

ÄŒLÃNEK:
{article_text}

PRAVIDLA PRO SCRIPT:
- Styl: pÅ™Ã¡telskÃ½, informativnÃ­, jako NotebookLM podcast
- DÃ©lka: 3-5 minut mluvenÃ©ho slova (cca 500-800 slov)
- ALEX zaÄÃ­nÃ¡, pÅ™edstavÃ­ tÃ©ma
- MAYA doplÅˆuje, klade otÃ¡zky, pÅ™idÃ¡vÃ¡ kontext
- StÅ™Ã­dajÃ­ se pÅ™irozenÄ›, ne mechanicky
- PouÅ¾Ã­vej hovorovou ÄeÅ¡tinu, ne spisovnou
- ZahrÅˆ vÅ¡echny dÅ¯leÅ¾itÃ© informace z ÄlÃ¡nku
- Konec: krÃ¡tkÃ© shrnutÃ­ a rozlouÄenÃ­

FORMÃT VÃSTUPU (pÅ™esnÄ› dodrÅ¾uj):
ALEX: [text]

MAYA: [text]

ALEX: [text]
...

ZaÄni pÅ™Ã­mo scriptem, bez Ãºvodu."""

    else:
        prompt = f"""Create a podcast script from the following article. Format: conversation between two hosts (ALEX and MAYA).

ARTICLE:
{article_text}

SCRIPT RULES:
- Style: friendly, informative, NotebookLM podcast style
- Length: 3-5 minutes of spoken word (approx 500-800 words)
- ALEX starts, introduces the topic
- MAYA adds context, asks questions, provides insights
- Natural back-and-forth, not mechanical
- Use conversational English
- Include all important information from the article
- End: brief summary and sign-off

OUTPUT FORMAT (follow exactly):
ALEX: [text]

MAYA: [text]

ALEX: [text]
...

Start directly with the script, no preamble."""

    try:
        message = client.messages.create(
            model=config.ARTICLE_MODEL,
            max_tokens=4000,
            temperature=0.8,
            messages=[{
                "role": "user",
                "content": prompt
            }]
        )

        script = message.content[0].text.strip()

        # Odhad ceny (Claude Haiku 4.5 pricing: $1.00/MTok input, $5.00/MTok output)
        cost_input = (message.usage.input_tokens / 1_000_000) * 1.00
        cost_output = (message.usage.output_tokens / 1_000_000) * 5.00
        total_cost = cost_input + cost_output

        return {
            'script': script,
            'tokens_in': message.usage.input_tokens,
            'tokens_out': message.usage.output_tokens,
            'cost': f"${total_cost:.4f}"
        }

    except Exception as e:
        return {'error': str(e)}
