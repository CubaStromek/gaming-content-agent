"""
Article Writer - generovani clanku z TOP temat
Stahne zdrojove clanky, posle do Claude a vygeneruje CZ + EN verzi
"""

import re
import requests
import anthropic
from bs4 import BeautifulSoup
from typing import List, Dict, Optional

import config
from urllib.parse import urlparse


def _build_sources_html(source_urls: List[str], lang: str = 'cs') -> str:
    """SestavÃ­ HTML sekci zdrojÅ¯ z reÃ¡lnÃ½ch URL."""
    if not source_urls:
        return ''

    heading = 'Zdroje' if lang == 'cs' else 'Sources'
    items = []
    for url in source_urls:
        try:
            domain = urlparse(url).netloc.replace('www.', '')
        except Exception:
            domain = url
        items.append(f'<li><a href="{url}" target="_blank" rel="noopener">{domain}</a></li>')

    return f'\n<h2>{heading}</h2>\n<ul>\n' + '\n'.join(items) + '\n</ul>'


def _strip_generated_sources(html: str) -> str:
    """OdstranÃ­ AI-generovanou sekci zdrojÅ¯ (Zdroje/Sources) pokud existuje."""
    # OdstranÃ­ <h2>Zdroje</h2> nebo <h2>Sources</h2> a nÃ¡sledujÃ­cÃ­ <ul>...</ul>
    return re.sub(
        r'\s*<h2>\s*(?:Zdroje|Sources)\s*</h2>\s*<ul>[\s\S]*?</ul>\s*',
        '',
        html,
        flags=re.IGNORECASE
    )


def scrape_full_article(url: str) -> str:
    """
    Stahne plny text clanku z URL

    Args:
        url: URL clanku

    Returns:
        Text clanku (max 3000 znaku)
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        resp = requests.get(url, headers=headers, timeout=15)
        resp.raise_for_status()

        soup = BeautifulSoup(resp.text, 'html.parser')

        # Odstran scripty a styly
        for tag in soup(['script', 'style', 'nav', 'footer', 'header', 'aside', 'iframe', 'noscript']):
            tag.decompose()

        # Zkus najit hlavni obsah
        content = None
        for selector in ['article', 'main', '[role="main"]', '.article-body', '.post-content', '.entry-content']:
            content = soup.select_one(selector)
            if content:
                break

        if not content:
            content = soup.body if soup.body else soup

        text = content.get_text(separator='\n', strip=True)

        # Vycisti prazdne radky
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        text = '\n'.join(lines)

        return text[:3000]

    except Exception as e:
        return f"[Chyba pri stahovani: {e}]"


def parse_topics_from_report(report_text: str) -> List[Dict]:
    """
    Parsuje text reportu na strukturovana temata

    Args:
        report_text: Plny text report.txt

    Returns:
        List slovniku s tematy
    """
    topics = []

    # Rozdeleni na bloky podle ğŸ® TÃ‰MA:
    blocks = re.split(r'(?=ğŸ® TÃ‰MA:)', report_text)

    for block in blocks:
        block = block.strip()
        if not block.startswith('ğŸ® TÃ‰MA:'):
            continue

        topic = {}

        # Parsuj jednotlive sekce
        patterns = {
            'topic': r'ğŸ® TÃ‰MA:\s*(.+)',
            'title': r'ğŸ“° NAVRÅ½ENÃ TITULEK:\s*(.+)',
            'angle': r'ğŸ¯ ÃšHEL POHLEDU:\s*(.+)',
            'context': r'ğŸ“ KONTEXT:\s*(.+)',
            'hook': r'ğŸ’¬ HLAVNÃ HOOK:\s*(.+)',
            'visual': r'ğŸ–¼ï¸ VIZUÃLNÃ NÃVRH:\s*(.+)',
            'virality': r'ğŸ”¥ VIRALITA:\s*(.+)',
            'why_now': r'ğŸ’¡ PROÄŒ TEÄKA:\s*(.+)',
            'seo_keywords': r'ğŸ·ï¸ SEO KLÃÄŒOVÃ SLOVA:\s*(.+)',
        }

        for key, pattern in patterns.items():
            match = re.search(pattern, block)
            topic[key] = match.group(1).strip() if match else ''

        # Parsuj virality score jako cislo
        virality_match = re.search(r'(\d+)', topic.get('virality', ''))
        topic['virality_score'] = int(virality_match.group(1)) if virality_match else 0

        # Parsuj zdroje (URL na samostatnych radcich)
        sources_section = re.search(r'ğŸ”— ZDROJE:\s*\n?([\s\S]*?)(?=ğŸ·ï¸|$)', block)
        if sources_section:
            urls = re.findall(r'https?://[^\s<>"\')\]]+[^\s<>"\')\].,]', sources_section.group(1))
            topic['sources'] = urls
        else:
            topic['sources'] = []

        if topic.get('topic'):
            topics.append(topic)

    return topics


def write_article(topic: Dict, source_texts: List[str]) -> Dict:
    """
    Vygeneruje clanek pomoci Claude API

    Args:
        topic: Slovnik s tematem (z parse_topics_from_report)
        source_texts: Seznam plnych textu zdrojovych clanku

    Returns:
        {"cs": "<html>...", "en": "<html>..."} nebo {"error": "..."}
    """
    client = anthropic.Anthropic(api_key=config.CLAUDE_API_KEY)

    # Pripravi zdrojove texty
    sources_combined = ""
    for i, text in enumerate(source_texts, 1):
        sources_combined += f"\n--- ZDROJ {i} ---\n{text}\n"

    # Pripravi seznam URL zdroju pro konec clanku
    source_urls = topic.get('sources', [])
    sources_list = "\n".join(source_urls)

    prompt = f"""NapÃ­Å¡ originÃ¡lnÃ­ hernÃ­ ÄlÃ¡nek na zÃ¡kladÄ› zdrojovÃ½ch textÅ¯.

TÃ‰MA: {topic.get('topic', '')}
NAVRÅ½ENÃ TITULEK: {topic.get('title', '')}
ÃšHEL POHLEDU: {topic.get('angle', '')}
KONTEXT: {topic.get('context', '')}
SEO KLÃÄŒOVÃ SLOVA: {topic.get('seo_keywords', '')}

ZDROJOVÃ‰ TEXTY:
{sources_combined}

PRAVIDLA:
- PiÅ¡ VLASTNÃMI SLOVY, ne kopÃ­ruj ze zdrojÅ¯
- ÄŒlÃ¡nek musÃ­ mÃ­t 600-1000 slov
- FormÃ¡t: HTML (h2 nadpisy, p odstavce, strong pro dÅ¯leÅ¾itÃ©)
- Styl: informativnÃ­, poutavÃ½, pro ÄeskÃ© hernÃ­ publikum
- ZahrÅˆ konkrÃ©tnÃ­ fakta a ÄÃ­sla ze zdrojÅ¯
- NEZMIÅ‡UJ zdroje v textu ÄlÃ¡nku (ne "podle IGN...")
- NEPÅ˜IDÃVEJ h1 nadpis - ten bude jako titulek ÄlÃ¡nku
- KRITICKÃ‰: V nadpisech (h2) NEPOUÅ½ÃVEJ Title Case! VelkÃ© pÃ­smeno POUZE na zaÄÃ¡tku vÄ›ty a u vlastnÃ­ch jmen. Å PATNÄš: "NovÃ¡ Ã‰ra Pro HernÃ­ PrÅ¯mysl". SPRÃVNÄš: "NovÃ¡ Ã©ra pro hernÃ­ prÅ¯mysl". Å PATNÄš: "What This Means For Players". SPRÃVNÄš: "What this means for players".
- NEPÅ˜IDÃVEJ sekci "Zdroje" ani "Sources" â€” odkazy na zdroje se pÅ™idajÃ­ automaticky

POSTUP:
1. NejdÅ™Ã­v napiÅ¡ ÄlÃ¡nek v ÄŒEÅ TINÄš (BEZ sekce zdrojÅ¯)
2. Potom PÅ˜ELOÅ½ celÃ½ ÄlÃ¡nek do angliÄtiny

=== ÄŒESKY ===
<ÄlÃ¡nek v ÄeÅ¡tinÄ› jako HTML>

=== ENGLISH ===
<pÅ™esnÃ½ pÅ™eklad ÄeskÃ©ho ÄlÃ¡nku vÃ½Å¡e>"""

    try:
        message = client.messages.create(
            model=config.ARTICLE_MODEL,
            max_tokens=4096,
            temperature=0.7,
            messages=[{
                "role": "user",
                "content": prompt
            }]
        )

        result_text = message.content[0].text

        # Parsuj CZ a EN casti
        cs_match = re.search(r'===\s*ÄŒESKY\s*===\s*([\s\S]*?)(?====\s*ENGLISH\s*===|$)', result_text)
        en_match = re.search(r'===\s*ENGLISH\s*===\s*([\s\S]*?)$', result_text)

        if cs_match:
            cs_html = cs_match.group(1).strip()
        elif en_match:
            cs_html = result_text[:en_match.start()].strip()
        else:
            cs_html = result_text
        en_html = en_match.group(1).strip() if en_match else ''

        # OdstraÅˆ AI-generovanÃ© zdroje a pÅ™ipoj reÃ¡lnÃ© URL
        cs_html = _strip_generated_sources(cs_html)
        cs_html += _build_sources_html(source_urls, 'cs')

        if en_html:
            en_html = _strip_generated_sources(en_html)
            en_html += _build_sources_html(source_urls, 'en')

        # Odhad ceny
        cost_input = (message.usage.input_tokens / 1_000_000) * 0.25
        cost_output = (message.usage.output_tokens / 1_000_000) * 1.25
        total_cost = cost_input + cost_output

        return {
            'cs': cs_html,
            'en': en_html,
            'tokens_in': message.usage.input_tokens,
            'tokens_out': message.usage.output_tokens,
            'cost': f"${total_cost:.4f}"
        }

    except Exception as e:
        return {'error': str(e)}


def generate_podcast_script(article_html: str, lang: str = 'cs') -> Dict:
    """
    Vygeneruje podcast script ze clanku (styl NotebookLM - 2 moderatori)

    Args:
        article_html: HTML obsah clanku
        lang: 'cs' pro cestinu, 'en' pro anglictinu

    Returns:
        {"script": "...", "tokens_in": ..., "tokens_out": ..., "cost": "..."} nebo {"error": "..."}
    """
    client = anthropic.Anthropic(api_key=config.CLAUDE_API_KEY)

    # Odstran HTML tagy pro citelnejsi vstup
    from bs4 import BeautifulSoup
    soup = BeautifulSoup(article_html, 'html.parser')
    article_text = soup.get_text(separator='\n', strip=True)

    if lang == 'cs':
        prompt = f"""VytvoÅ™ podcast script ze nÃ¡sledujÃ­cÃ­ho ÄlÃ¡nku. FormÃ¡t: konverzace dvou moderÃ¡torÅ¯ (ALEX a MAYA).

ÄŒLÃNEK:
{article_text}

PRAVIDLA PRO SCRIPT:
- Styl: pÅ™Ã¡telskÃ½, informativnÃ­, jako NotebookLM podcast
- DÃ©lka: 3-5 minut mluvenÃ©ho slova (cca 500-800 slov)
- ALEX zaÄÃ­nÃ¡, pÅ™edstavÃ­ tÃ©ma
- MAYA doplÅˆuje, klade otÃ¡zky, pÅ™idÃ¡vÃ¡ kontext
- StÅ™Ã­dajÃ­ se pÅ™irozenÄ›, ne mechanicky
- PouÅ¾Ã­vej hovorovou ÄeÅ¡tinu, ne spisovnou
- ZahrÅˆ vÅ¡echny dÅ¯leÅ¾itÃ© informace z ÄlÃ¡nku
- Konec: krÃ¡tkÃ© shrnutÃ­ a rozlouÄenÃ­

FORMÃT VÃSTUPU (pÅ™esnÄ› dodrÅ¾uj):
ALEX: [text]

MAYA: [text]

ALEX: [text]
...

ZaÄni pÅ™Ã­mo scriptem, bez Ãºvodu."""

    else:
        prompt = f"""Create a podcast script from the following article. Format: conversation between two hosts (ALEX and MAYA).

ARTICLE:
{article_text}

SCRIPT RULES:
- Style: friendly, informative, NotebookLM podcast style
- Length: 3-5 minutes of spoken word (approx 500-800 words)
- ALEX starts, introduces the topic
- MAYA adds context, asks questions, provides insights
- Natural back-and-forth, not mechanical
- Use conversational English
- Include all important information from the article
- End: brief summary and sign-off

OUTPUT FORMAT (follow exactly):
ALEX: [text]

MAYA: [text]

ALEX: [text]
...

Start directly with the script, no preamble."""

    try:
        message = client.messages.create(
            model=config.ARTICLE_MODEL,
            max_tokens=4000,
            temperature=0.8,
            messages=[{
                "role": "user",
                "content": prompt
            }]
        )

        script = message.content[0].text.strip()

        # Odhad ceny (Haiku pricing)
        cost_input = (message.usage.input_tokens / 1_000_000) * 0.25
        cost_output = (message.usage.output_tokens / 1_000_000) * 1.25
        total_cost = cost_input + cost_output

        return {
            'script': script,
            'tokens_in': message.usage.input_tokens,
            'tokens_out': message.usage.output_tokens,
            'cost': f"${total_cost:.4f}"
        }

    except Exception as e:
        return {'error': str(e)}
